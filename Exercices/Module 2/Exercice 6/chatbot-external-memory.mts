import { BaseMessage, HumanMessage, RemoveMessage, SystemMessage } from "@langchain/core/messages";
import { END, START, StateGraph } from "@langchain/langgraph";
import { ChatOpenAI } from "@langchain/openai";
import "dotenv/config";
import { mkdirSync } from "fs";
import { dirname } from "path";

if (!process.env.OPENAI_API_KEY) {
  throw new Error("OPENAI_API_KEY n'est pas d√©fini dans l'environnement");
}

const model = new ChatOpenAI({ model: "gpt-4o", temperature: 0 });

// ============================================================================
// SQLITE : BASE DE DONN√âES EXTERNE
// ============================================================================
// SqliteSaver permet de persister l'√©tat dans une base de donn√©es SQLite.
// Contrairement √† MemorySaver, les donn√©es survivent aux red√©marrages.

const dbPath = "state_db/example.db";

// Cr√©er le dossier state_db s'il n'existe pas
try {
  mkdirSync(dirname(dbPath), { recursive: true });
} catch (e) {
  // Le dossier existe d√©j√†, c'est OK
}

// Importer SqliteSaver et better-sqlite3
import { SqliteSaver } from "@langchain/langgraph-checkpoint-sqlite";
import Database from "better-sqlite3";

// Cr√©er la connexion SQLite
const conn = new Database(dbPath);

// Cr√©er le checkpointer SQLite
const memory = new SqliteSaver(conn);

// ============================================================================
// √âTAT AVEC MESSAGES ET R√âSUM√â
// ============================================================================

type State = {
  messages: BaseMessage[];
  summary: string;
};

// Reducer pour messages : ajoute les messages √† la liste
function addMessages(
  current: BaseMessage[],
  update: BaseMessage | BaseMessage[]
): BaseMessage[] {
  const messagesToAdd = Array.isArray(update) ? update : [update];
  const result = [...current];
  
  // G√©rer RemoveMessage pour supprimer des messages
  for (const msg of messagesToAdd) {
    if (msg instanceof RemoveMessage) {
      // Supprimer le message avec l'ID correspondant
      const index = result.findIndex((m) => m.id === msg.id);
      if (index !== -1) {
        result.splice(index, 1);
      }
    } else {
      // Si le message a un ID et qu'un message avec le m√™me ID existe, le remplacer
      if (msg.id) {
        const existingIndex = result.findIndex((m) => m.id === msg.id);
        if (existingIndex !== -1) {
          result[existingIndex] = msg;
        } else {
          result.push(msg);
        }
      } else {
        // Ajouter le nouveau message
        result.push(msg);
      }
    }
  }
  
  return result;
}

// Reducer pour summary : √©crase la valeur
function updateSummary(current: string, update: string): string {
  return update;
}

// ============================================================================
// N≈íUD : APPELER LE MOD√àLE
// ============================================================================

async function call_model(state: State): Promise<Partial<State>> {
  const summary = state.summary || "";

  let messages: BaseMessage[];

  if (summary) {
    const systemMessage = new SystemMessage({
      content: `Summary of conversation earlier: ${summary}`,
    });
    messages = [systemMessage, ...state.messages];
  } else {
    messages = state.messages;
  }

  const response = await model.invoke(messages);
  return { messages: [response] };
}

// ============================================================================
// N≈íUD : R√âSUMER LA CONVERSATION
// ============================================================================

async function summarize_conversation(state: State): Promise<Partial<State>> {
  const existingSummary = state.summary || "";

  let summaryPrompt: string;
  if (existingSummary) {
    summaryPrompt = `This is summary of the conversation to date: ${existingSummary}\n\nExtend the summary by taking into account the new messages above:`;
  } else {
    summaryPrompt = "Create a summary of the conversation above:";
  }

  const messagesWithPrompt = [...state.messages, new HumanMessage({ content: summaryPrompt })];
  const response = await model.invoke(messagesWithPrompt);
  const newSummary = typeof response.content === "string" ? response.content : "";

  const messagesToRemove = state.messages.slice(0, -2);
  const removeMessages = messagesToRemove.map((m) => new RemoveMessage({ id: m.id || "" }));

  return {
    summary: newSummary,
    messages: removeMessages,
  };
}

// ============================================================================
// AR√äTE CONDITIONNELLE : D√âCIDER SI ON R√âSUME OU ON TERMINE
// ============================================================================

type NextNode = "summarize_conversation" | typeof END;

function should_continue(state: State): NextNode {
  const messages = state.messages;

  if (messages.length > 6) {
    return "summarize_conversation";
  }

  return END;
}

// ============================================================================
// CONSTRUCTION DU GRAPHE
// ============================================================================

const builder = new StateGraph<State>({
  channels: {
    messages: {
      default: () => [],
      reducer: addMessages,
    },
    summary: {
      default: () => "",
      reducer: updateSummary,
    },
  },
});

builder.addNode("conversation", call_model);
builder.addNode("summarize_conversation", summarize_conversation);

builder.addEdge(START as any, "conversation" as any);
builder.addConditionalEdges("conversation" as any, should_continue as any);
builder.addEdge("summarize_conversation" as any, END as any);

// Compiler le graphe avec SqliteSaver pour la persistance externe
export const graph = builder.compile({ checkpointer: memory as any });

// ============================================================================
// D√âMONSTRATION : CONVERSATION AVEC PERSISTANCE SQLITE
// ============================================================================

if (import.meta.url === `file://${process.argv[1]}` || process.argv[1]?.includes("chatbot-external-memory")) {
  (async () => {
    const config = { configurable: { thread_id: "1" } };

    console.log("=== D√©but de la conversation ===\n");
    console.log(`üìÅ Base de donn√©es SQLite: ${dbPath}\n`);

    // Premier message
    console.log("1. Utilisateur: hi! I'm Lance");
    let output = await graph.invoke(
      {
        messages: [new HumanMessage({ content: "hi! I'm Lance" })],
        summary: "",
      },
      config
    );
    const lastMessage = output.messages[output.messages.length - 1];
    console.log(`   Assistant: ${typeof lastMessage.content === "string" ? lastMessage.content : ""}\n`);

    // Deuxi√®me message
    console.log("2. Utilisateur: what's my name?");
    output = await graph.invoke(
      {
        messages: [new HumanMessage({ content: "what's my name?" })],
      },
      config
    );
    const lastMessage2 = output.messages[output.messages.length - 1];
    console.log(`   Assistant: ${typeof lastMessage2.content === "string" ? lastMessage2.content : ""}\n`);

    // Troisi√®me message
    console.log("3. Utilisateur: i like the 49ers!");
    output = await graph.invoke(
      {
        messages: [new HumanMessage({ content: "i like the 49ers!" })],
      },
      config
    );
    const lastMessage3 = output.messages[output.messages.length - 1];
    console.log(`   Assistant: ${typeof lastMessage3.content === "string" ? lastMessage3.content : ""}\n`);

    // V√©rifier l'√©tat sauvegard√© dans SQLite
    console.log("=== V√©rification de l'√©tat sauvegard√© ===\n");
    const state = await graph.getState(config);
    console.log("√âtat sauvegard√© dans SQLite:");
    console.log(`  - Nombre de messages: ${state.values.messages.length}`);
    console.log(`  - R√©sum√©: "${state.values.summary || "(vide)"}"`);
    console.log(`  - Thread ID: ${config.configurable.thread_id}`);
    console.log("‚úÖ L'√©tat est persistant dans la base de donn√©es SQLite !\n");

    console.log("üí° Vous pouvez red√©marrer le script et l'√©tat sera toujours disponible !");
    console.log("üí° La base de donn√©es SQLite persiste m√™me apr√®s la fermeture du processus.\n");
  })();
}

